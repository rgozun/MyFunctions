# Features Metadata
def metadata(df_input,AutoClass,nUniqLim):
    ColDtypes = []
    
    # Identify Datatype
    ColDtypes = pd.DataFrame(df_input.dtypes)
    ColDtypes.reset_index(inplace=True)
    ColDtypes.columns = ['Feature','DataType']
    
    # label Feature a Factor If Less or Equal To nUniqLim
    if AutoClass == False:
        ColDtypes['Factor'] = np.nan
        
        # Identify Number of Unique Values
        ColDtypes['nUnique'] = np.nan
        for row in range(0,len(ColDtypes)):
            ColDtypes.iloc[row,3] = df_input[ColDtypes.iloc[row,0]].nunique()
    else:
        # Flag If Factor
        ColDtypes['Factor'] = np.nan
        for row in range(0,len(ColDtypes)):
            if df_input[ColDtypes.iloc[row,0]].nunique() <= nUniqLim:
                ColDtypes.iloc[row,2] = 1
            else:
                ColDtypes.iloc[row,2] = 0
        # Identify Number of Unique Values
        ColDtypes['nUnique'] = np.nan
        for row in range(0,len(ColDtypes)):
            if ColDtypes.iloc[row,2] == 1:
                ColDtypes.iloc[row,3] = df_input[ColDtypes.iloc[row,0]].nunique()
            else:
                ColDtypes.iloc[row,3] = 'NotFactor'

    # Count Nulls
    ColDtypes['nNulls'] = np.nan
    for row in range(0,len(ColDtypes)):   
        ColDtypes.iloc[row,4] = df_input[ColDtypes.iloc[row,0]].isnull().sum()

    # Null Percent
    ColDtypes['PercentNulls'] = np.nan
    for row in range(0,len(ColDtypes)):
        ColDtypes.iloc[row,5] = round((ColDtypes.iloc[row,4] / len(df_input)) * 100, 1)
        
    # Remove column Factor if AutoClass==False
    if AutoClass == False:
        ColDtypes = ColDtypes.drop(columns='Factor')
    else:
        pass

    return(ColDtypes)

# Correlation Matrix 1
def my_corrmat(df_input):
    sns.set_theme(style="white")

    # Compute the correlation matrix
    corrmat = df_input.corr()

    # Generate a mask for the upper triangle
    mask = np.triu(np.ones_like(corrmat, dtype=bool))

    # Set up the matplotlib figure
    f, ax = plt.subplots(figsize=(11, 9))

    # Generate a custom diverging colormap
    cmap = sns.diverging_palette(230, 20, as_cmap=True)

    # Draw the heatmap with the mask and correct aspect ratio
    sns.heatmap(corrmat, mask=mask, cmap=cmap, center=0,
                square=True, linewidths=.5, cbar_kws={"shrink": .5})
    
    # Correlation Coefficients output
    #corrmat.to_csv(r'Correlation Matrix 2 - r_scores.txt', sep='|', header=True, index=True)
   
# Correlation Matrix 2
    warnings.filterwarnings('ignore')

    def corrdot(*args, **kwargs, df_input):
        corr_r = args[0].corr(args[1], 'pearson')
        corr_text = f"{corr_r:2.2f}".replace("0.", ".")
        ax = plt.gca()
        ax.set_axis_off()
        marker_size = abs(corr_r) * 10000
        ax.scatter([.5], [.5], marker_size, [corr_r], alpha=0.6, cmap="coolwarm",
                   vmin=-1, vmax=1, transform=ax.transAxes)
        font_size = abs(corr_r) * 40 + 5
        ax.annotate(corr_text, [.5, .5,],  xycoords="axes fraction",
                    ha='center', va='center', fontsize=font_size)

    sns.set(style='white', font_scale=1.6)
    g = sns.PairGrid(df_input, aspect=1.4, diag_sharey=False)
    g.map_lower(sns.regplot, lowess=True, ci=False, line_kws={'color': 'black'})
    g.map_diag(sns.distplot, kde_kws={'color': 'black'})
    g.map_upper(corrdot)

# Quick Preview of Classifiers: Random Forest, SVM, Logit, Decision Tree
def ClassifierBoot():
    classifiers = []

    model1 = RandomForestClassifier()
    classifiers.append(model1)

    model2 = svm.SVC()
    classifiers.append(model2)
    
    model3 = LogisticRegression(max_iter=400)
    classifiers.append(model3)
    
    model4 = tree.DecisionTreeClassifier()
    classifiers.append(model4)

    for clf in classifiers:
        clf.fit(X_train, y_train)
        y_pred= clf.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        print("Accuracy of %s is %s"%(clf, acc))
        cm = confusion_matrix(y_test, y_pred)

        print("Confusion Matrix of %s is %s"%(clf, cm))

# Check Null Counts
df.isnull().sum()
